@article{Liu2022,
   abstract = {An adaptive optics scanning laser ophthalmoscope (AOSLO) has the characteristics of a high resolution and a small field of view (FOV), which are greatly affected by eye motion. Continual eye motion will cause distortions both within the frame (intra-frame) and between frames (inter-frame). Overcoming eye motion and achieving image stabilization is the first step and is of great importance in image analysis. Although cross-correlation-based methods enable image registration to be achieved, the manual identification and distinguishing of images with saccades is required; manual registration has a high accuracy, but it is time-consuming and complicated. Some imaging systems are able to compensate for eye motion during the imaging process, but special hardware devices need to be integrated into the system. In this paper, we proposed a deep-learning-based algorithm for automatic image stabilization. The algorithm used the VGG-16 network to extract convolution features and a correlation filter to detect the position of reference in the next frame, and finally, it compensated for displacement to achieve registration. According to the results, the mean difference in the vertical and horizontal displacement between the algorithm and manual registration was 0.07 pixels and 0.16 pixels, respectively, with a 95% confidence interval of (−3.26 px, 3.40 px) and (−4.99 px, 5.30 px). The Pearson correlation coefficients for the vertical and horizontal displacements between these two methods were 0.99 and 0.99, respectively. Compared with cross-correlation-based methods, the algorithm had a higher accuracy, automatically removed images with blinks, and corrected images with saccades. Compared with manual registration, the algorithm enabled manual registration accuracy to be achieved without manual intervention.},
   author = {Shudong Liu and Zhenghao Ji and Yi He and Jing Lu and Gongpu Lan and Jia Cong and Xiaoyu Xu and Boyu Gu},
   doi = {10.3390/info13110531},
   issn = {20782489},
   issue = {11},
   journal = {Information (Switzerland)},
   keywords = {VGG-16,adaptive optics scanning laser ophthalmoscope,deep learning,eye motion,image stabilization},
   month = {11},
   publisher = {MDPI},
   title = {Deep-Learning Image Stabilization for Adaptive Optics Ophthalmoscopy},
   volume = {13},
   year = {2022},
}
@article{Zhang2021,
   abstract = {Microaneurysms (MAs) are one of the earliest signs of diabetic retinopathy (DR), a frequent complication of diabetes that can lead to visual impairment and blindness. Adaptive optics scanning laser ophthalmoscopy (AOSLO) provides real-time retinal images with resolution down to 2 $\mu m$ and thus allows detection of the morphologies of individual MAs, a potential marker that might dictate MA pathology and affect the progression of DR. In contrast to the numerous automatic models developed for assessing the number of MAs on fundus photographs, currently there is no high throughput image protocol available for automatic analysis of AOSLO photographs. To address this urgency, we introduce AOSLO-net, a deep neural network framework with customized training policies to automatically segment MAs from AOSLO images. We evaluate the performance of AOSLO-net using 87 DR AOSLO images and our results demonstrate that the proposed model outperforms the state-of-the-art segmentation model both in accuracy and cost and enables correct MA morphological classification.},
   author = {Qian Zhang and Konstantina Sampani and Mengjia Xu and Shengze Cai and Yixiang Deng and He Li and Jennifer K. Sun and George Em Karniadakis},
   month = {6},
   title = {AOSLO-net: A deep learning-based method for automatic segmentation of retinal microaneurysms from adaptive optics scanning laser ophthalmoscope images},
   url = {http://arxiv.org/abs/2106.02800},
   year = {2021},
}
@article{Cunefare2019,
   abstract = {Quantification of the human rod and cone photoreceptor mosaic in adaptive optics scanning light ophthalmoscope (AOSLO) images is useful for the study of various retinal pathologies. Subjective and time-consuming manual grading has remained the gold standard for evaluating these images, with no well validated automatic methods for detecting individual rods having been developed. We present a novel deep learning based automatic method, called the rod and cone CNN (RAC-CNN), for detecting and classifying rods and cones in multimodal AOSLO images. We test our method on images from healthy subjects as well as subjects with achromatopsia over a range of retinal eccentricities. We show that our method is on par with human grading for detecting rods and cones. © 2019 Optical Society of America under the terms of the OSA Open Access Publishing Agreement.},
   author = {David Cunefare and Alison L. Huckenpahler and Emily J. Patterson and Alfredo Dubra and Joseph Carroll and Sina Farsiu},
   doi = {10.1364/boe.10.003815},
   issn = {2156-7085},
   issue = {8},
   journal = {Biomedical Optics Express},
   month = {8},
   pages = {3815},
   publisher = {The Optical Society},
   title = {RAC-CNN: multimodal deep learning based automatic detection and classification of rod and cone photoreceptors in adaptive optics scanning light ophthalmoscope images},
   volume = {10},
   year = {2019},
}
@article{Nakatake2019,
   abstract = {Purpose The purpose of the study was to investigate the characteristics of the parafoveal cone density changes in patients with retinitis pigmentosa (RP) using adaptive optics scanning laser ophthalmoscopy (AO-SLO). Methods A total of 14 eyes of RP patients and 10 eyes of control subjects were examined. High-resolution images of cone photoreceptor cells were obtained with a Canon AO-SLO system in the four retinal regions of the superior, inferior, temporal, and nasal areas located 1.0 mm from the central fovea. The relationships of cone density with optical coherence tomography (OCT) findings and the visual sensitivity of the static perimetry tests were analyzed in RP patients. Results The averaged cone densities in RP patients were decreased at 1.0 mm eccentricity from the fovea (11,899 cells/mm2) compared with those in control subjects (16,647 cells/mm2; P < 0.01). The cone density was substantially decreased even in RP patients with an intact interdigitation zone at the examined area (12,865 cells/mm2; P < 0.01 vs. controls) and preserved visual sensitivity with > 35 dB (13,019 cells/mm2; P < 0.001 vs. controls). Conclusions In RP, cone photoreceptor cell loss occurred in the parafoveal region with a preserved EZ/IZ or visual sensitivity. AO-SLO may be a useful modality to detect early changes of cone photoreceptor cells in RP patients.},
   author = {Shunji Nakatake and Yusuke Murakami and Jun Funatsu and Yoshito Koyanagi and Masato Akiyama and Yukihide Momozawa and Tatsuro Ishibashi and Koh Hei Sonoda and Yasuhiro Ikeda},
   doi = {10.1007/S00417-019-04307-0},
   issn = {1435702X},
   issue = {6},
   journal = {Graefe's Archive for Clinical and Experimental Ophthalmology},
   keywords = {Adaptive optics scanning laser ophthalmoscopy (AO-SLO),Cone density,Cone photoreceptor cell,Retinitis pigmentosa},
   month = {6},
   pages = {1169-1181},
   pmid = {30937533},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Early detection of cone photoreceptor cell loss in retinitis pigmentosa using adaptive optics scanning laser ophthalmoscopy},
   volume = {257},
   year = {2019},
}
@article{Davidson2018,
   abstract = {We present a robust deep learning framework for the automatic localisation of cone photoreceptor cells in Adaptive Optics Scanning Light Ophthalmoscope (AOSLO) split-detection images. Monitoring cone photoreceptors with AOSLO imaging grants an excellent view into retinal structure and health, provides new perspectives into well known pathologies, and allows clinicians to monitor the effectiveness of experimental treatments. The MultiDimensional Recurrent Neural Network (MDRNN) approach developed in this paper is the first method capable of reliably and automatically identifying cones in both healthy retinas and retinas afflicted with Stargardt disease. Therefore, it represents a leap forward in the computational image processing of AOSLO images, and can provide clinical support in on-going longitudinal studies of disease progression and therapy. We validate our method using images from healthy subjects and subjects with the inherited retinal pathology Stargardt disease, which significantly alters image quality and cone density. We conduct a thorough comparison of our method with current state-of-the-art methods, and demonstrate that the proposed approach is both more accurate and appreciably faster in localizing cones. As further validation to the method's robustness, we demonstrate it can be successfully applied to images of retinas with pathologies not present in the training data: achromatopsia, and retinitis pigmentosa.},
   author = {Benjamin Davidson and Angelos Kalitzeos and Joseph Carroll and Alfredo Dubra and Sebastien Ourselin and Michel Michaelides and Christos Bergeles},
   doi = {10.1038/s41598-018-26350-3},
   issn = {20452322},
   issue = {1},
   journal = {Scientific Reports},
   month = {12},
   pmid = {29784939},
   publisher = {Nature Publishing Group},
   title = {Automatic Cone Photoreceptor Localisation in Healthy and Stargardt Afflicted Retinas Using Deep Learning},
   volume = {8},
   year = {2018},
}
@article{Cunefare2017,
   abstract = {Imaging with an adaptive optics scanning light ophthalmoscope (AOSLO) enables direct visualization of the cone photoreceptor mosaic in the living human retina. Quantitative analysis of AOSLO images typically requires manual grading, which is time consuming, and subjective; thus, automated algorithms are highly desirable. Previously developed automated methods are often reliant on ad hoc rules that may not be transferable between different imaging modalities or retinal locations. In this work, we present a convolutional neural network (CNN) based method for cone detection that learns features of interest directly from training data. This cone-identifying algorithm was trained and validated on separate data sets of confocal and split detector AOSLO images with results showing performance that closely mimics the gold standard manual process. Further, without any need for algorithmic modifications for a specific AOSLO imaging system, our fully-automated multi-modality CNN-based cone detection method resulted in comparable results to previous automatic cone segmentation methods which utilized ad hoc rules for different applications. We have made free open-source software for the proposed method and the corresponding training and testing datasets available online.},
   author = {David Cunefare and Leyuan Fang and Robert F. Cooper and Alfredo Dubra and Joseph Carroll and Sina Farsiu},
   doi = {10.1038/s41598-017-07103-0},
   issn = {20452322},
   issue = {1},
   journal = {Scientific Reports},
   month = {12},
   pmid = {28747737},
   publisher = {Nature Publishing Group},
   title = {Open source software for automatic detection of cone photoreceptors in adaptive optics ophthalmoscopy using convolutional neural networks},
   volume = {7},
   year = {2017},
}
@article{Roorda1988,
   abstract = {We present the first scanning laser ophthalmoscope that uses adaptive optics to measure and correct the high order aberrations of the human eye. Adaptive optics increases both lateral and axial resolution, permitting axial sectioning of retinal tissue in vivo. The instrument is used to visualize photoreceptors, nerve fibers and flow of white blood cells in retinal capillaries.},
   author = {Austin Roorda and Fernando Romero-Borja and William J Donnelly and Hope Queener and Thomas J Hebert and Melanie C W Campbell and G R H W Webb and O Hughes and W J Donnelly and F Romero-Borja and A Roorda},
   pages = {3-14},
   publisher = {Kugler & Ghedini Publications},
   title = {Adaptive optics scanning laser ophthalmoscopy},
   volume = {7},
   url = {http://www.opt.uh.edu/research/aroorda/aoslo.htm,},
   year = {1988},
   journal={Report}
}

@article{ToledoCortes2023,
  title = {Deep Density Estimation for Cone Counting and Diagnosis of Genetic Eye Diseases From Adaptive Optics Scanning Light Ophthalmoscope Images},
  author = {Santiago Toledo-Cortés and Adam M. Dubis and Fabio A. González and Henning Müller},
  journal = {Translational Vision Science I\& Technology},
  volume = {12},
  number = {11},
  pages = {25},
  year = {2023},
  month = {November},
  doi = {10.1167/tvst.12.11.25},
  url = {https://doi.org/10.1167/tvst.12.11.25},
  keywords = {cone density estimation, retinitis pigmentosa, Stargardt’s disease, diagnosis, deep density estimation},
  received = {2023-03-09},
  accepted = {2023-10-02},
  published = {2023-11-20},
  abstract = {Adaptive optics scanning light ophthalmoscope (AOSLO) imaging offers a microscopic view of the living retina, holding promise for diagnosing and researching eye diseases like retinitis pigmentosa and Stargardt’s disease. The technology’s clinical impact of AOSLO hinges on early detection through automated analysis tools. We introduce Cone Density Estimation (CoDE) and CoDE for Diagnosis (CoDED). CoDE is a deep density estimation model for cone counting that estimates a density function whose integral is equal to the number of cones. CoDED is an integration of CoDE with deep image classifiers for diagnosis. We use two AOSLO image datasets to train and evaluate the performance of cone density estimation and classification models for retinitis pigmentosa and Stargardt’s disease. Bland-Altman plots show that CoDE outperforms state-of-the-art models for cone density estimation. CoDED reported an F1 score of 0.770 ± 0.04 for disease classification, outperforming traditional convolutional networks. CoDE shows promise in classifying the retinitis pigmentosa and Stargardt’s disease cases from a single AOSLO image. Our preliminary results suggest the potential role of analyzing patterns in the retinal cellular mosaic to aid in the diagnosis of genetic eye diseases. Our study explores the potential of deep density estimation models to aid in the analysis of AOSLO images. Although the initial results are encouraging, more research is needed to fully realize the potential of such methods in the treatment and study of genetic retinal pathologies.}
}

@article{Xie2018,
author = {Xie, Weidi and Noble, Julia and Zisserman, Andrew},
year = {2016},
month = {05},
pages = {1-10},
title = {Microscopy cell counting and detection with fully convolutional regression networks},
journal = {Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization},
doi = {10.1080/21681163.2016.1149104}
}

@article{Kulyabin2024,
   title={Generalist Segmentation Algorithm for Photoreceptors Analysis in Adaptive Optics Imaging},
   journal={Electrical Engineering and Systems Science},
   ISBN={9783031781049},
   ISSN={1611-3349},
   url={http://dx.doi.org/10.1007/978-3-031-78104-9_12},
   DOI={10.1007/978-3-031-78104-9_12},
   booktitle={Pattern Recognition},
   publisher={Springer Nature Switzerland},
   author={Kulyabin, Mikhail and Sindel, Aline and Pedersen, Hilde R. and Gilson, Stuart and Baraas, Rigmor and Maier, Andreas},
   year={2024},
   month=dec, pages={168–182} }

@article{Amann2020,
  title={Explainability for Artificial Intelligence in Healthcare: A Multidisciplinary Perspective},
  author={Julia Amann and Alessandro Blasimme and Effy Vayena and Dietmar Frey and Vince I. Madai and {the Precise4Q Consortium}},
  journal={BMC Medical Informatics and Decision Making},
  volume={20},
  number={1},
  pages={310},
  year={2020},
  month={11},
  doi={10.1186/s12911-020-01332-6},
  issn={1472-6947},
  url={https://doi.org/10.1186/s12911-020-01332-6},
  pmid={33256715},
  pmcid={PMC7706009},
  abstract={Background: The uptake of Artificial Intelligence (AI) in healthcare has been accompanied by concerns about the transparency and the explainability of AI-driven clinical decision-making. A variety of stakeholders have called for explainability as a requirement for clinical AI systems. However, different stakeholders - AI developers, clinicians, ethics and policy experts - may have different notions of what constitutes good explanations, and different requirements for explainability. This multidisciplinary study addresses this gap by examining explainability expectations across stakeholder groups.}
}

@article{Antoniadi2021,
  title={Current Challenges and Future Opportunities for XAI in Machine Learning-Based Clinical Decision Support Systems: A Systematic Review},
  author={Anna Markella Antoniadi and Yuhan Du and Yasmine Guendouz and Lan Wei and Claudia Mazo and Brett A. Becker and Catherine Mooney},
  journal={Applied Sciences},
  volume={11},
  number={11},
  pages={5088},
  year={2021},
  month={5},
  doi={10.3390/app11115088},
  issn={2076-3417},
  url={https://doi.org/10.3390/app11115088},
  publisher={MDPI},
  abstract={Machine Learning (ML) and, more generally, Artificial Intelligence (AI) methods have been successfully applied to clinical decision support tasks, achieving performances often comparable with or surpassing those of human experts. However, the complexity and lack of interpretability of the most accurate ML models makes clinicians question their reliability and impedes their integration into clinical practice. To overcome this, the field of eXplainable AI (XAI) has emerged to help make AI and ML systems more understandable to humans. This systematic review presents the current state of XAI in healthcare, identifies key challenges, and proposes a roadmap for future research.}
}